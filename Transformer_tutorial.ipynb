{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8296e231-f46d-4646-8821-6a188a7bb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family=\"NanumBarunGothic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab065354-2ca1-4fe1-9eb3-c039534616b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hoya9\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from transformers import MarianMTModel, MarianTokenizer # translation machine\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math, random\n",
    "from einops import rearrange\n",
    "\n",
    "DEVICE = \"GPU\" if torch.cuda.is_available() else \"CPU\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c8bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # Multi-GPU case\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da12c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer & model\n",
    "tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ko-en')\n",
    "model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ko-en') # MT: Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158f7887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eos_idx =  0\n",
      "pad_idx =  65000\n"
     ]
    }
   ],
   "source": [
    "eos_idx = tokenizer.eos_token_id\n",
    "pad_idx = tokenizer.pad_token_id\n",
    "print('eos_idx = ', eos_idx)\n",
    "print('pad_idx = ', pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b90c7",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc9f2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1bjbeWgqlVKJ9gzDcL1hfD9cIItQy9_N2\n",
      "From (redirected): https://drive.google.com/uc?id=1bjbeWgqlVKJ9gzDcL1hfD9cIItQy9_N2&confirm=t&uuid=6e6e21aa-0449-4743-bca5-c7c6f69f607a\n",
      "To: c:\\Users\\hoya9\\OneDrive\\Desktop\\torch-gpu\\Workspace\\Transformer-pytorch\\data\\Transformer_small.pt\n",
      "\n",
      "  0%|          | 0.00/448M [00:00<?, ?B/s]\n",
      "  0%|          | 524k/448M [00:00<02:39, 2.82MB/s]\n",
      "  1%|          | 2.62M/448M [00:00<00:44, 9.98MB/s]\n",
      "  2%|▏         | 7.34M/448M [00:00<00:21, 20.7MB/s]\n",
      "  2%|▏         | 9.96M/448M [00:00<00:19, 22.4MB/s]\n",
      "  3%|▎         | 14.7M/448M [00:00<00:14, 29.3MB/s]\n",
      "  4%|▍         | 17.8M/448M [00:00<00:14, 29.0MB/s]\n",
      "  5%|▍         | 21.0M/448M [00:00<00:16, 25.3MB/s]\n",
      "  5%|▌         | 24.1M/448M [00:01<00:16, 25.7MB/s]\n",
      "  6%|▌         | 27.3M/448M [00:01<00:18, 23.2MB/s]\n",
      "  7%|▋         | 31.5M/448M [00:01<00:15, 27.5MB/s]\n",
      "  8%|▊         | 34.6M/448M [00:01<00:19, 21.5MB/s]\n",
      "  9%|▊         | 38.8M/448M [00:01<00:16, 25.6MB/s]\n",
      " 10%|▉         | 43.0M/448M [00:01<00:13, 29.0MB/s]\n",
      " 11%|█         | 47.2M/448M [00:01<00:12, 31.8MB/s]\n",
      " 11%|█▏        | 51.4M/448M [00:01<00:11, 33.3MB/s]\n",
      " 12%|█▏        | 55.1M/448M [00:02<00:17, 22.0MB/s]\n",
      " 13%|█▎        | 59.2M/448M [00:02<00:15, 25.6MB/s]\n",
      " 14%|█▍        | 63.4M/448M [00:02<00:13, 28.8MB/s]\n",
      " 15%|█▌        | 67.6M/448M [00:02<00:12, 31.4MB/s]\n",
      " 16%|█▌        | 71.3M/448M [00:02<00:14, 26.8MB/s]\n",
      " 17%|█▋        | 75.5M/448M [00:02<00:12, 29.8MB/s]\n",
      " 18%|█▊        | 79.2M/448M [00:02<00:11, 31.3MB/s]\n",
      " 18%|█▊        | 82.8M/448M [00:03<00:15, 23.8MB/s]\n",
      " 19%|█▉        | 86.0M/448M [00:03<00:18, 19.1MB/s]\n",
      " 20%|██        | 90.7M/448M [00:03<00:15, 22.9MB/s]\n",
      " 21%|██        | 94.9M/448M [00:03<00:14, 24.5MB/s]\n",
      " 22%|██▏       | 98.0M/448M [00:04<00:20, 17.3MB/s]\n",
      " 23%|██▎       | 103M/448M [00:04<00:15, 22.2MB/s] \n",
      " 24%|██▍       | 107M/448M [00:04<00:13, 26.2MB/s]\n",
      " 25%|██▌       | 113M/448M [00:04<00:10, 32.2MB/s]\n",
      " 26%|██▌       | 117M/448M [00:04<00:13, 24.3MB/s]\n",
      " 27%|██▋       | 122M/448M [00:04<00:11, 28.4MB/s]\n",
      " 28%|██▊       | 126M/448M [00:05<00:17, 18.2MB/s]\n",
      " 29%|██▉       | 131M/448M [00:05<00:14, 22.5MB/s]\n",
      " 30%|██▉       | 134M/448M [00:05<00:16, 19.2MB/s]\n",
      " 31%|███       | 139M/448M [00:05<00:12, 24.4MB/s]\n",
      " 32%|███▏      | 145M/448M [00:05<00:11, 26.3MB/s]\n",
      " 33%|███▎      | 150M/448M [00:05<00:09, 31.0MB/s]\n",
      " 34%|███▍      | 154M/448M [00:06<00:09, 32.5MB/s]\n",
      " 35%|███▌      | 158M/448M [00:06<00:08, 34.6MB/s]\n",
      " 36%|███▋      | 164M/448M [00:06<00:07, 37.4MB/s]\n",
      " 38%|███▊      | 168M/448M [00:06<00:07, 39.1MB/s]\n",
      " 38%|███▊      | 172M/448M [00:06<00:07, 36.4MB/s]\n",
      " 40%|███▉      | 177M/448M [00:06<00:07, 37.2MB/s]\n",
      " 40%|████      | 181M/448M [00:06<00:10, 25.3MB/s]\n",
      " 42%|████▏     | 187M/448M [00:07<00:08, 30.3MB/s]\n",
      " 43%|████▎     | 191M/448M [00:07<00:07, 32.7MB/s]\n",
      " 44%|████▎     | 196M/448M [00:07<00:07, 32.3MB/s]\n",
      " 44%|████▍     | 199M/448M [00:07<00:08, 31.1MB/s]\n",
      " 46%|████▌     | 204M/448M [00:07<00:06, 36.1MB/s]\n",
      " 47%|████▋     | 210M/448M [00:07<00:05, 39.9MB/s]\n",
      " 48%|████▊     | 214M/448M [00:07<00:05, 41.8MB/s]\n",
      " 49%|████▉     | 220M/448M [00:07<00:05, 44.6MB/s]\n",
      " 50%|█████     | 225M/448M [00:07<00:04, 46.3MB/s]\n",
      " 51%|█████▏    | 230M/448M [00:08<00:04, 47.1MB/s]\n",
      " 52%|█████▏    | 235M/448M [00:08<00:04, 45.4MB/s]\n",
      " 54%|█████▎    | 240M/448M [00:08<00:05, 35.5MB/s]\n",
      " 55%|█████▍    | 245M/448M [00:08<00:05, 39.2MB/s]\n",
      " 56%|█████▌    | 251M/448M [00:08<00:04, 41.8MB/s]\n",
      " 57%|█████▋    | 256M/448M [00:08<00:04, 44.0MB/s]\n",
      " 58%|█████▊    | 262M/448M [00:08<00:03, 46.8MB/s]\n",
      " 60%|█████▉    | 267M/448M [00:08<00:03, 45.9MB/s]\n",
      " 61%|██████    | 273M/448M [00:09<00:03, 48.9MB/s]\n",
      " 62%|██████▏   | 279M/448M [00:09<00:03, 50.1MB/s]\n",
      " 63%|██████▎   | 284M/448M [00:09<00:03, 50.8MB/s]\n",
      " 65%|██████▍   | 289M/448M [00:09<00:03, 42.0MB/s]\n",
      " 66%|██████▌   | 294M/448M [00:09<00:03, 43.0MB/s]\n",
      " 67%|██████▋   | 300M/448M [00:09<00:03, 45.2MB/s]\n",
      " 68%|██████▊   | 305M/448M [00:09<00:04, 32.0MB/s]\n",
      " 69%|██████▉   | 309M/448M [00:10<00:04, 31.0MB/s]\n",
      " 70%|███████   | 314M/448M [00:10<00:03, 35.5MB/s]\n",
      " 71%|███████   | 318M/448M [00:10<00:03, 33.8MB/s]\n",
      " 72%|███████▏  | 322M/448M [00:10<00:05, 21.4MB/s]\n",
      " 73%|███████▎  | 327M/448M [00:10<00:04, 24.8MB/s]\n",
      " 74%|███████▍  | 332M/448M [00:10<00:04, 28.8MB/s]\n",
      " 75%|███████▍  | 336M/448M [00:11<00:04, 26.8MB/s]\n",
      " 76%|███████▌  | 339M/448M [00:11<00:04, 23.3MB/s]\n",
      " 76%|███████▋  | 342M/448M [00:11<00:05, 20.5MB/s]\n",
      " 77%|███████▋  | 347M/448M [00:11<00:04, 24.1MB/s]\n",
      " 78%|███████▊  | 351M/448M [00:11<00:03, 28.7MB/s]\n",
      " 79%|███████▉  | 355M/448M [00:12<00:04, 21.5MB/s]\n",
      " 80%|████████  | 360M/448M [00:12<00:03, 27.2MB/s]\n",
      " 81%|████████▏ | 365M/448M [00:12<00:02, 31.2MB/s]\n",
      " 82%|████████▏ | 370M/448M [00:12<00:03, 24.8MB/s]\n",
      " 84%|████████▎ | 375M/448M [00:12<00:02, 29.5MB/s]\n",
      " 84%|████████▍ | 379M/448M [00:12<00:02, 27.7MB/s]\n",
      " 85%|████████▌ | 382M/448M [00:12<00:02, 24.2MB/s]\n",
      " 86%|████████▋ | 387M/448M [00:13<00:02, 26.8MB/s]\n",
      " 87%|████████▋ | 391M/448M [00:13<00:02, 27.8MB/s]\n",
      " 88%|████████▊ | 396M/448M [00:13<00:01, 33.0MB/s]\n",
      " 89%|████████▉ | 401M/448M [00:13<00:01, 35.9MB/s]\n",
      " 91%|█████████ | 406M/448M [00:13<00:01, 39.8MB/s]\n",
      " 92%|█████████▏| 411M/448M [00:13<00:01, 34.7MB/s]\n",
      " 93%|█████████▎| 416M/448M [00:13<00:00, 37.8MB/s]\n",
      " 94%|█████████▍| 422M/448M [00:13<00:00, 41.8MB/s]\n",
      " 95%|█████████▌| 426M/448M [00:14<00:00, 35.1MB/s]\n",
      " 96%|█████████▌| 430M/448M [00:14<00:00, 36.1MB/s]\n",
      " 97%|█████████▋| 435M/448M [00:14<00:00, 32.3MB/s]\n",
      " 99%|█████████▊| 442M/448M [00:14<00:00, 42.0MB/s]\n",
      "100%|█████████▉| 447M/448M [00:14<00:00, 40.5MB/s]\n",
      "100%|██████████| 448M/448M [00:14<00:00, 30.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1M0yYP2umxlwaAbk_iq5G_Z5y3qLu9Wet\n",
      "To: c:\\Users\\hoya9\\OneDrive\\Desktop\\torch-gpu\\Workspace\\Transformer-pytorch\\data\\Transformer_small_history.pt\n",
      "\n",
      "  0%|          | 0.00/1.39k [00:00<?, ?B/s]\n",
      "100%|██████████| 1.39k/1.39k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64 # 실제 논문에선 2.5만 token이 한 batch에 담기게 했다고 함\n",
    "LAMBDA = 0 # l2-Regularization를 위한 hyperparams (저장된 모델)\n",
    "EPOCH = 15 # 저장된 모델\n",
    "max_len = 100 # 길이 제한 (GPU 부담도 많이 감소)\n",
    "\"\"\"\n",
    "decoder에서 모델이 <eos>가 출력되는 것까지는 Loss를 구하고,\n",
    "그뒤 <pad>에 대한 Loss는 무시하기 위한 역활\n",
    "즉, label이 <pad> 일 때는 무시\n",
    "\"\"\"\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "scheduler_name = 'Noam' # Transformer 논문 제 2저자가 제안한 learning rate scheduler\n",
    "scheduler_name = 'Cos'\n",
    "#### Noam ####\n",
    "# warmup_steps = 4000 # 실제 논문에서 제시한 값 (총 10만 step의 4%)\n",
    "warmup_steps = 1000 # 데이터 수 * EPOCH / BS = 총 step 수 인것 고려 (저장된 모델)\n",
    "LR_scale = .5 # Noam scheduler에 peak LR 값 조절을 위해 곱해질 값 (저장된 모델)\n",
    "#### Cos ####\n",
    "LR_init = 5e-4\n",
    "T0 = 1500 # 첫 주기\n",
    "T_mult = 2 # 배 만큼 주기가 길어짐 (1보다 큰 정수여야 함)\n",
    "#############\n",
    "\n",
    "\"\"\"\n",
    "나만의 모델을 만들고 싶으면,\n",
    "new_model_train = True\n",
    "prev_model_use = False\n",
    "\"\"\"\n",
    "new_model_train = False\n",
    "prev_model_use = True\n",
    "\n",
    "!mkdir data\n",
    "\n",
    "if prev_model_use:\n",
    "    !gdown https://drive.google.com/uc?id=1bjbeWgqlVKJ9gzDcL1hfD9cIItQy9_N2 -O data/Transformer_small.pt\n",
    "    !gdown https://drive.google.com/uc?id=1M0yYP2umxlwaAbk_iq5G_Z5y3qLu9Wet -O data/Transformer_small_history.pt\n",
    "\n",
    "    save_model_path = 'data/Transformer_small.pt'\n",
    "    save_history_path = 'data/Transformer_small_history.pt'\n",
    "else:\n",
    "    save_model=path = 'data/Transformer_small2.pt'\n",
    "    save_history_path = 'data/Transformer_small2_history.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1803d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "논문에 나오는 BASE MODEL\n",
    "train loss를 많이 줄이려면 많은 epoch이 요구됨.\n",
    "test 성능도 높이려면 더 많은 데이터가 필요함\n",
    "\"\"\"\n",
    "n_layers = 6\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "n_heads = 8\n",
    "drop_p = .1\n",
    "\n",
    "# 좀 사이즈 줄인 모델 (훈련된 input_embedding, fc_out 사용하면 사용 불가)\n",
    "n_layers = 3\n",
    "d_model = 26\n",
    "d_ff = 512\n",
    "n_heads = 8\n",
    "drop_p = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcc2e5",
   "metadata": {},
   "source": [
    "## 토크나이저 & 학습된 모델 써보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d2ecbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁H', 'i', ',', '▁I', \"'\", 'm', '▁I', 'an', '.', '▁', '...', '▁a', '▁a', '?']\n",
      "['▁a', '/', 'b', '▁1', '+2', '+3', '▁2:', '1', '▁a', '>', 'b']\n",
      "['▁p', 're', 'tra', 'in', 'ed', '▁re', 'st', 'art']\n",
      "['▁ch', 'at', 'G', 'P', 'T']\n",
      "['▁The', '▁', 'ex', 'am', 'ple', '▁is', '▁', 'very', '▁good', '▁in', '▁', 'our', '▁', 'le', 'c', 'ture']\n",
      "['▁한', '글', '은', '▁어떻게', '▁할까', '?']\n",
      "['▁확실히', '▁띄', '어', '쓰기', '▁기준으로', '▁토', '크', '나이', '징', '을', '▁하는', '▁것', '▁같', '진', '▁않다', '.']\n",
      "['▁여러분', '▁차례', '!']\n"
     ]
    }
   ],
   "source": [
    "# tokenizer 써보기 (_로 띄어쓰기를 나타낸다! 즉, _가 없으면 이어진 한 단어 : subword tokenizing)\n",
    "# tokenizer에 대한 참고 자료: https://ratsgo.github.io/nlpbook/docs/preprocess/bpe/\n",
    "print(tokenizer.tokenize(\"Hi, I'm Ian. ... a  a?\"))\n",
    "print(tokenizer.tokenize('a/b 1+2+3 2:1 a>b'))\n",
    "print(tokenizer.tokenize('pretrained restart'))\n",
    "print(tokenizer.tokenize('chatGPT'))\n",
    "print(tokenizer.tokenize('The example is very good in our lecture'))\n",
    "print(tokenizer.tokenize('한글은 어떻게 할까?'))\n",
    "print(tokenizer.tokenize('확실히 띄어쓰기 기준으로 토크나이징을 하는 것 같진 않다.'))\n",
    "print(tokenizer.tokenize('여러분 차례!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed4cd73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65001\n",
      "[34359]\n",
      "[65000]\n",
      "[0]\n",
      "[125]\n",
      "[59]\n",
      "['▁문장', '을', '▁넣으면', '▁to', 'k', 'en', 'ize', '해서', '▁숫자', '로', '▁바꾼', '다']\n",
      "[13774, 51, 40068, 5, 1479, 1252, 5016, 969, 6635, 131, 30737, 161]\n",
      "사람\n",
      "으로\n",
      "make\n",
      "</s> <unk> ., the to of? and s a' in 들<pad> <unk> <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "# print(tokenizer.get_vocab()) # tokenizer에 들어있는 모든 토큰과 토큰의 해당하는 번호를 dict으로 가짐\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print((vocab_size))\n",
    "\n",
    "# add_special_token은 <eos> 자동 붙여주는 것을 방지\n",
    "print(tokenizer.encode('지능', add_special_tokens=False))   # string to index\n",
    "print(tokenizer.encode('<pad>', add_special_tokens=False))  # <pad>는 65000\n",
    "print(tokenizer.encode('</s>', add_special_tokens=False))   # <sos> or <eos>는 0\n",
    "print(tokenizer.encode('He', add_special_tokens=False))\n",
    "print(tokenizer.encode('he', add_special_tokens=False))     # 대소문자 다른 단어로 인식\n",
    "print(tokenizer.tokenize('문장을 넣으면 tokenize해서 숫자로 바꾼다'))\n",
    "print(tokenizer.encode('문장을 넣으면 tokenize해서 숫자로 바꾼다', add_special_tokens=False))\n",
    "print(tokenizer.decode([204]))\n",
    "print(tokenizer.decode([206]))\n",
    "print(tokenizer.decode([210]))\n",
    "print(tokenizer.decode(list(range(15)) + [65000, 65001, 65002, 65003]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1244ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 지금 너무 배고프다... 치킨먹고 싶다!\n",
      "번역 결과: I'm so hungry right now... and I want chicken!\n"
     ]
    }
   ],
   "source": [
    "# 사전 학습된 모델로 번역\n",
    "input_text = \"지금 너무 배고프다... 치킨먹고 싶다!\"\n",
    "\n",
    "input_tokens = tokenizer.encode(input_text, return_tensors=\"pt\")    # 모델에서 weight와 행렬곱을 하기 위해 2차원 벡터로 변경경\n",
    "translated_tokens = model.generate(input_tokens, max_new_tokens=max_len)    # max_len까지만 출력\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)  # <pad> </s> <unk> 같은 특수 토큰은 출력에서 제외외\n",
    "\n",
    "print(\"입력:\", input_text)\n",
    "print(\"번역 결과:\", translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1513ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1r4ZnFJOStyBlNRx7snBQ-Iq2GNyJKL6t\n",
      "To: c:\\Users\\hoya9\\OneDrive\\Desktop\\torch-gpu\\Workspace\\Transformer-pytorch\\data\\dialogue.xlsx\n",
      "\n",
      "  0%|          | 0.00/9.57M [00:00<?, ?B/s]\n",
      "  5%|▌         | 524k/9.57M [00:00<00:02, 3.02MB/s]\n",
      " 27%|██▋       | 2.62M/9.57M [00:00<00:00, 10.8MB/s]\n",
      " 49%|████▉     | 4.72M/9.57M [00:00<00:00, 13.9MB/s]\n",
      "100%|██████████| 9.57M/9.57M [00:00<00:00, 19.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "# data download\n",
    "# https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=126 데이터 경로\n",
    "!gdown https://drive.google.com/uc?id=1r4ZnFJOStyBlNRx7snBQ-Iq2GNyJKL6t -O data/dialogue.xlsx\n",
    "data = pd.read_excel('data/dialogue.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee50e2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 7)\n",
      "    대분류 소분류       상황  Set Nr.  발화자                            원문  \\\n",
      "0  비즈니스  회의  의견 교환하기        1  A-1   이번 신제품 출시에 대한 시장의 반응은 어떤가요?   \n",
      "1  비즈니스  회의  의견 교환하기        1  B-1    판매량이 지난번 제품보다 빠르게 늘고 있습니다.   \n",
      "2  비즈니스  회의  의견 교환하기        1  A-2  그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요.   \n",
      "\n",
      "                                                 번역문  \n",
      "0  How is the market's reaction to the newly rele...  \n",
      "1  The sales increase is faster than the previous...  \n",
      "2  Then, we'll have to call the manufacturer and ...  \n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94007baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97000\n",
      "2000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.loc[idx, '원문'], self.data.loc[idx, '번역문']\n",
    "\n",
    "custom_DS = CustomDataset(data)\n",
    "\n",
    "train_DS, val_DS, test_DS = torch.utils.data.random_split(custom_DS, [97000, 2000, 1000])\n",
    "# 논문에서는 450만개 영, 독 문장 pair 사용\n",
    "\n",
    "train_DL = torch.utils.data.DataLoader(train_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_DL = torch.utils.data.DataLoader(val_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_DL = torch.utils.data.DataLoader(test_DS, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(len(train_DS))\n",
    "print(len(val_DS))\n",
    "print(len(test_DS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b55c07b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스: 19993\n",
      "원문: 나도 그랬으면 좋겠지만 겨울까지 휴가 못 가.\n",
      "영문: I wish I could, but I can't go on vacation until winter.\n"
     ]
    }
   ],
   "source": [
    "# test_DS 확인\n",
    "i = 5\n",
    "src_text, trg_text = test_DS[i]\n",
    "\n",
    "print(f\"인덱스: {test_DS.indices[i]}\")   # 원본 데이터에서의 인덱스 추척\n",
    "print(f\"원문: {src_text}\")\n",
    "print(f\"영문: {trg_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a2ca7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('어서 오세요. 환전 도와드리겠습니다. 여권 보여주시겠어요?', '너희 표는 어디에서 구했냐? 난 찾다가 포기했는데.', '건너편에서 항구행 버스를 타시면 금방 갈 겁니다.', '오늘이 우리 5주년 기념일인 거 잊지 않았지?', '어댑터만 따로 판매하고 있지 않습니다.', '제가 아는 소프트웨어 프로그래머가 있는데 추천할만한 프로그램이 있는지 물어볼게요.', '내 말이 그 말이야. 인터넷 면세점으로 구매한 물건도 받으러 가야 하는데.', '751이나 740 버스를 타면 정문 앞에서 내려줘요.', '저희 헬스장에 댄스 프로그램이 있으니 그걸 같이 들어보시면 될 것 같아요.', '키랑 몸무게가 어떻게 되는지 아세요?', '돈가스 포장해주세요, 6분 뒤에 가지러 올게요.', '퇴사라는 어려운 결정을 하셨는데, 사유가 무엇인지 말씀해주시겠습니까?', '그럼 내가 여기선 찌개를 사고 후식을 사도록 할게.', '차고지 앞 정류장에서 버스를 타시면 됩니다.', '소설의 장면들을 어떻게 풀어나갈지 정말 궁금해.', '하지만 소셜 미디어에서도 반응이 좋은데요.', '우선 문제가 뭔지 정확하게 말해 주시면 고맙겠습니다.', '혹시 몇 번 상영관이었는지 기억하시나요?', '졸업식 끝나고 외식을 하려는데, 뭐 먹고 싶은 거 있나요?', '이번 주에 신제품 관련해서 홍보팀 회의 일정을 잡아주시겠어요?', '이 원피스는 가을 느낌이 나는데, 여름 느낌이 나는 원피스는 없나요?', '보니까 아예 화면 대부분이 안 보이는 상태인데, 혹시 떨어뜨리셨나요?', '대학병원에서는 당일 접수가 어렵습니다.', '아니 무슨 날은 아니고, 그냥 분위기 전환 삼아 꾸며봤어.', '잠시만요, 지금 앞에 환자가 많이 밀려있어서요.', '항생제를 함께 처방해주셨는데, 염증이 심하신가 봐요?', '아니요, 유럽 전문 인솔자가 공항에서부터 동행합니다.', '이메일이 전송되고 원하신다면 문자를 보내 드릴 수도 있어요.', '감사합니다, 여성 인권도 다양한 분야가 있는데 어떠한 부분으로 할까요?', '그렇군요. 역시 면세점이라서 그런지 시중보다 훨씬 저렴한 것 같아요.', '업무상 사고로 처리되니 보험 처리는 너무 걱정하지 마시고 영수증만 제출해주세요.', '카드로 결제를 하면 수수료가 이중으로 들어서, 양해를 바랍니다.', '시청역에 가려고 하는데 표는 어떻게 사면 됩니까?', '아까 제 배낭을 잃어버렸는데 여기에 있나 왔어요.', '물론입니다, 깨끗하고 편리한 샤워 시설이 갖춰져 있습니다.', '나도 이곳에 올 때마다 느끼는 건데, 어쩔 수 없지.', '어제 반지 주문을 하였는데, 혹시 디자인을 수정해도 될까요?', '이사 중 분실로 재발급 받았었고, 이전 여권은 찾아서 시청에 반납했어요.', '2km라니, 그렇게 먼 길을 어떻게 걸어서 간다는 거야?', '오늘 스페셜 이벤트 중인 카드로 구매하시는 건가요?', '수화물 크기를 재봐야 하는데, 먼저 올려주세요.', '2층까지 자리가 꽉 차있다고? 그럼 다른 데 가야지.', '거기 있는 체크무늬 셔츠는 18,000원이에요.', '우산은 기내에 들고 못 타는 거로 알고 있었는데 바뀌었나 봐요.', '구매한 지 일주일이 넘지 않았고, 미사용 상태거든요?', '이튿날 현장으로 바로 합류하셨던 거였죠?', '검토 한 번 더 한 후에 저한테 메일로 전송해달라고 말씀드렸잖아요.', '제가 이렇게 잘하시는 사장님 따라가려면 아직 먼 것 같아요.', '아니요, 이번이 처음인데요.', '알았어, 내가 나중에 중국어 인사를 하면 너도 따라서 말해야 해.', '마사지 받을 시간 없을 때 발만이라도 해야겠어.', '네, 맞습니다, 어떤 용건으로 전화 주셨습니까?', '제가 앞에 있는 차를 들이받았습니다.', '한 곳을 제외하고는 모두 무료 셔틀버스를 운행하고 있습니다.', '아니요, 입원과 퇴원 당일 5시간만 무료주차 됩니다.', '호텔에서 출발하는 공항버스는 몇 시에 있습니까?', '네. 제 짐을 잘 부탁드립니다.', '여자 친구분이 색조 화장을 자주 하신다면, 이 아이섀도 팔레트는 어떠세요?', '미세먼지 때문에 사무실 공기가 안 좋은 것 같네요.', '누수가 계속돼서 바닥에 물이 고이는 문제가 있습니다.', '이번 시험은 듣기 파트가 있어서 각자 개개인의 이어폰을 준비하셔야 합니다.', '제가 일할 때 지금 보내드린 사이트를 많이 참고하는 편인데, 한 번 훑어보세요.', '작년에는 같은 시간표로 운영됐는데 또 모르지요.', '포장지가 보이는 것처럼 2종류밖에 없어요.')\n",
      "(\"Hello, I'll help you with the currency exchange. Could you show me your passport?\", 'Where did you get your ticket? I tried to find it for quite a while but had to give up.', 'You can take the bus to the port across the street.', \"You didn't forget that today is our 5th anniversary, right?\", \"We don't sell adapters separately.\", \"I know a software programmer and I'll ask if there's a program he can recommend.\", \"That's what I mean. I need to retrieve the duty-free items I bought online.\", \"If you take the bus 751 or 740, it'll take you to the front gate.\", \"We have a dance program at our gym, so why don't you take that together?\", 'Do you know what your height and weight are?', \"One tonkatsu to go please, and I'll be back to pick it up in 5 minutes.\", 'You made a difficult decision to leave the company, could you tell me the reason?', \"Then I'll buy the stew here and up the ante by buying dessert.\", 'You can take a bus from the stop in front of the garage.', \"I'm really curious about how they will recreate the scenes in the novel.\", 'But I see great responses on social media as well.', \"First of all, I'd like it if you could tell me exactly what problem occurred.\", 'By chance do you remember which number screen it was?', 'I am planning to eat after graduation, is there something you would like to eat?', 'Could you schedule a PR team meeting for the new product this week?', 'This one-piece dress has a fall feel, do you have any that feels like summer?', 'I see that most of the screen is dying, did you happen to drop it?', 'Same-day registrations are difficult at university hospitals.', \"It's not a special day, I just wanted a change in the atmosphere.\", 'Hold on, we have too many patients before you.', 'You are prescribed antibiotics, your inflammation must be severe?', 'No, a professional guide for Europe will be accompanying you.', 'The e-mail is sent and I can also send a text if you want.', \"Thank you. There is a variety of areas for Women's rights, what area would be good?\", 'I see. It seems much cheaper than in other shops because this is a duty-free shop.', \"It is treated as a work accident, so don't worry about the insurance, you can just hand in a receipt.\", 'If you pay by credit card, the fee will be doubled so please understand.', 'How can I buy a ticket to go to the city hall?', 'I forgot my backpack earlier, so is it here by any chance?', 'Of course, there are clean and convenient shower facilities.', 'I feel that too whenever I come here, but I have no choice.', 'I ordered a ring yesterday but may I change its design?', 'I was reissued because I lost it while I was moving, and I found the old passport and returned it to the City Hall.', \"It's 2km, so how are we going to walk such a long-distance?\", \"Are you purchasing with one of today's special event cards?\", 'I need to check the size of your luggage, so please put it on first.', \"If the 2nd floor is packed too, then tet's go somewhere else then.\", 'That checkered shirt over there is 18,000 won.', \"I thought we can't bring an umbrella into an airplane but it seems like the rules have changed.\", \"But, I bought it less than a week ago, and it hasn't been used.\", 'Did you join us on the site on the second day right?', 'I asked you to review it again and send it to me via e-mail.', \"It's a long way for me to catch up with you the president who plays so well.\", \"No, it's my first time.\", 'Okay, but you should follow suit when I say bye in Chinese later.', \"When I don't have enough time for massage, I will just get a foot massage.\", \"Yes, that's right, can I ask what you are calling for?\", 'I hit the car in front of me.', 'We are operating the free shuttle bus except for one place.', 'No, only 5 hours of free parking is provided on the first day and last day of hospitalization.', 'What time is the airport bus leaving from the hotel?', 'Sure. Please take care of my stuff.', 'If your girlfriend often partakes in heavy makeup, how about this eye shadow palette?', 'The air in the office seems bad because of the fine dust.', \"There's a problem with water on the floor because of continuous leaks.\", 'Everyone has to prepare their own earphones because this exam includes listening part.', 'I look at the sites I sent you when I work, look through them.', 'It ran on the same timetable last year, but you can never be sure.', 'As you can see we only have 2 types of wrapping paper.')\n",
      "64\n",
      "64\n",
      "tensor([[ 2256, 26857,     2, 11947,   503,  9279, 35894,     2, 43359,  3541,\n",
      "         24687,     7, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "         65000],\n",
      "        [  636,  8194,    55, 25224, 42396,  1996,     7,   285,  7810,  1435,\n",
      "          8089,  4692,     2, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "         65000]])\n",
      "tensor([[    0,  1753, 12506,   965,     3,    16,    12,   226,  3963,  2242,\n",
      "          1438,    18,    33,     4,     9, 11783, 16370,  1252, 15489,     9,\n",
      "          5691,  3309,  1132,  5303,     2,  6609,  2021,   173,    18, 13845,\n",
      "          5259,    75,    69,  1835,  8283, 10613,     7,     0, 65000, 65000,\n",
      "         65000, 65000, 65000, 65000, 65000, 65000, 65000],\n",
      "        [    0,  1278,  3539,   101,   155,    18,   167,    69,  2718,  8717,\n",
      "          2866,     7,    16,     9, 12493,   194,     5,  1731, 16772,    24,\n",
      "            26,     9, 11303,  4773,    11,     9, 22614, 10745,    99,  3963,\n",
      "          3154,     5,  2441,  2652,   119,     2,     0, 65000, 65000, 65000,\n",
      "         65000, 65000, 65000, 65000, 65000, 65000, 65000]])\n",
      "torch.Size([64, 21])\n",
      "torch.Size([64, 47])\n",
      "tensor([65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000, 65000,     0, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000])\n",
      "</s> I was reissued because I lost it while I was moving, and I found the old passport and returned it to the City Hall.</s>\n",
      "tensor([    0,    16,   121,    11,   100,  9652,  2196,  9111,  5502,  9404,\n",
      "         2135,  9437,     8,    16,    12,   226,    50,  1479,     9,  4257,\n",
      "          109,    12,    10,    11,  5502,  9404,  2135,    59,    67,  1640,\n",
      "         8440,   107,  6296,     2,     0, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000])\n",
      "tensor([   16,   121,    11,   100,  9652,  2196,  9111,  5502,  9404,  2135,\n",
      "         9437,     8,    16,    12,   226,    50,  1479,     9,  4257,   109,\n",
      "           12,    10,    11,  5502,  9404,  2135,    59,    67,  1640,  8440,\n",
      "          107,  6296,     2,     0, 65000, 65000, 65000, 65000, 65000, 65000,\n",
      "        65000, 65000, 65000, 65000, 65000, 65000])\n"
     ]
    }
   ],
   "source": [
    "# train_DL TEST\n",
    "for src_texts, trg_texts in train_DL:\n",
    "    print(src_texts)\n",
    "    print(trg_texts)\n",
    "    print(len(src_texts))\n",
    "    print(len(trg_texts))\n",
    "\n",
    "\n",
    "    # 여러 문장에 대해서는 tokenizer.encode() 가 아닌 그냥 tokenizer()사용\n",
    "    # add_special_tokens = True (default)면 <eos>를 붙임\n",
    "    # truncation = True: max_len 보다 길면 끊음\n",
    "    src = tokenizer(src_texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt', add_special_tokens=False).input_ids\n",
    "    # <sos>가 tokenizer에 따로 없어서 </s> 를 <sos> 로서 사용\n",
    "    trg_texts = ['</s> '+ s for s in trg_texts]\n",
    "    trg = tokenizer(trg_texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt', add_special_tokens=True).input_ids\n",
    "\n",
    "    print(src[:2])\n",
    "    print(trg[:2])\n",
    "    print(src.shape)\n",
    "    print(trg.shape)\n",
    "    print(trg[:,-1])    # 가장 마지막 단어를 보니 어떤 문장은 <eos> 로 끝이 났고 나머지는 <pad> 로 끝이 났다는 걸 볼 수 있음\n",
    "    print(tokenizer.decode(trg[trg[:,-1]==eos_idx,:][0]))   # 가장 긴 문장들 중 첫 번째 문장 관찰\n",
    "    print(trg[5,:-1])  # 디코더 입력\n",
    "    print(trg[5,1:])   # 디코더 출력으로 나와야 할 label\n",
    "    # 어차피 출력으로 pad token이 기다리고 있으니 loss에서 ignore로 인해 다 무시되므로 eos가 들어가도 상관없음\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6bd8f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 나도 그랬으면 좋겠지만 겨울까지 휴가 못 가.\n",
      "정답: I wish I could, but I can't go on vacation until winter.\n",
      "AI의 번역: <pad> I wish I could, but I can't go on vacation until winter.</s>\n"
     ]
    }
   ],
   "source": [
    "# 내가 쓸 train data 에 대해서 MarianMTmodel이 잘 번역하는지 확인\n",
    "src_text, trg_text = test_DS[5]\n",
    "print(f\"입력: {src_text}\")\n",
    "print(f\"정답: {trg_text}\")\n",
    "\n",
    "src = tokenizer.encode(src_text, return_tensors='pt', add_special_tokens=True)\n",
    "# add_special_tokens = False 해보면 뭔가 이상하게 번역함 (학습 때 source에도 <eos>를 넣었단 증거?)\n",
    "translated_tokens = model.generate(src, max_new_tokens=max_len)\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=False)\n",
    "\n",
    "print(f\"AI의 번역: {translated_text}\")  # 디코더 첫 입력으로 <pad> 토큰을 넣었음. (<pad>를 <sos>로 사용)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f91b8",
   "metadata": {},
   "source": [
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8bf59",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.fc_q = nn.Linear(d_model, d_model)\n",
    "        self.fc_k = nn.Linear(d_model, d_model)\n",
    "        self.fc_v = nn.Linear(d_model, d_model)\n",
    "        self.fc_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.tensor(d_model / n_heads))\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "\n",
    "        Q = self.fc_q(Q) # 개단차\n",
    "        K = self.fc_k(K)\n",
    "        V = self.fc_v(V)\n",
    "\n",
    "        Q = rearrange(Q, '개 단 (헤 차) -> 개 헤 단 차', 헤=self.n_heads) # 개단차 -> 개헤단차\n",
    "        K = rearrange(K, '개 단 (헤 차) -> 개 헤 단 차', 헤=self.n_heads)\n",
    "        V = rearrange(V, '개 단 (헤 차) -> 개 헤 단 차', 헤=self.n_heads)\n",
    "\n",
    "        attention_score = Q @ K.transpose(-2,-1)/self.scale # 개헤단단\n",
    "\n",
    "        if mask is not None:\n",
    "            attention_score[mask] = -1e10\n",
    "\n",
    "        attention_weights = torch.softmax(attention_score, dim=-1) # 개헤단단\n",
    "\n",
    "        attention = attention_weights @ V # 개헤단차\n",
    "\n",
    "        X = rearrange(attention, '개 헤 단 차 -> 개 단 (헤 차)') # 개헤단차 -> 개단차\n",
    "        x = self.fc_o(X) # 개단차\n",
    "\n",
    "        return x, attention_weights\n",
    "\n",
    "class FF(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(drop_p), # 논문에는 명시하진 않았지만, overfitting에 취약한 부분이기 때문에 추가\n",
    "                                    nn.Linear(d_ff, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576240d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 1,  4],\n",
      "         [ 2,  5],\n",
      "         [ 3,  6]],\n",
      "\n",
      "        [[ 7, 10],\n",
      "         [ 8, 11],\n",
      "         [ 9, 12]]])\n",
      "tensor([[[ 1,  4],\n",
      "         [ 2,  5],\n",
      "         [ 3,  6]],\n",
      "\n",
      "        [[ 7, 10],\n",
      "         [ 8, 11],\n",
      "         [ 9, 12]]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940b8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-GPU",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
